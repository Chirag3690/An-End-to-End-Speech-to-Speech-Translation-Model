{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthesizer.inference import Synthesizer\n",
    "from encoder import inference as encoder\n",
    "from vocoder import inference as vocoder\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import os\n",
    "import librosa\n",
    "import sounddevice as sd\n",
    "import wavio\n",
    "import glob\n",
    "from helper import draw_embed, create_spectrogram, read_audio\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Record your own voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recording...\")\n",
    "duration = 5  # seconds\n",
    "fs = 48000\n",
    "sd.default.samplerate = fs\n",
    "sd.default.channels = 1\n",
    "myrecording = sd.rec(int(duration * fs))\n",
    "sd.wait(duration)\n",
    "print(\"Saving sample as myvoice.mp3\")\n",
    "path_myrecording = \"./samples/myvoice.mp3\"\n",
    "wavio.write(path_myrecording, myrecording, fs, sampwidth=2)\n",
    "sd.play(myrecording, fs) #st\n",
    "print(\"Done! Saved sample as myvoice.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = create_spectrogram(path_myrecording)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load your pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading pretrained models...\")\n",
    "seed = 42\n",
    "low_mem = False\n",
    "num_generated = 0\n",
    "enc_model_fpath = Path(\"encoder/saved_models/pretrained.pt\")\n",
    "syn_model_dir = Path(\"synthesizer/saved_models/logs-pretrained/\")\n",
    "voc_model_fpath = Path(\"vocoder/saved_models/pretrained/pretrained.pt\")\n",
    "encoder.load_model(enc_model_fpath)\n",
    "synthesizer = Synthesizer(\n",
    "    syn_model_dir.joinpath(\"taco_pretrained\"), low_mem=low_mem, seed=seed\n",
    ")\n",
    "vocoder.load_model(voc_model_fpath)\n",
    "print(\"Loaded pretrained models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Choose a recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_folder = \"samples\"\n",
    "filenames = glob.glob(os.path.join(audio_folder, \"*.mp3\"))\n",
    "print(filenames)\n",
    "\n",
    "selected_filename = 'samples/myvoice.mp3'\n",
    "in_fpath = Path(selected_filename.replace('\"', \"\").replace(\"'\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Start preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_wav, sampling_rate = librosa.load(str(in_fpath))\n",
    "preprocessed_wav = encoder.preprocess_wav(original_wav, sampling_rate)\n",
    "print(\"Loaded file succesfully!\")\n",
    "embed = encoder.embed_utterance(preprocessed_wav)\n",
    "sd.play(original_wav, sampling_rate) #st\n",
    "print(\"Created the embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = draw_embed(embed, \"myembedding\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Synthesize the text you like to hear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating the spectrogram\n",
    "text = input(\"Write a sentence (+-20 words) to be synthesized:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if text != \"\":\n",
    "    texts = [text]\n",
    "    embeds = [embed]\n",
    "    # If you know what the attention layer alignments are,\n",
    "    # you can retrieve them here by passing return_alignments=True\n",
    "    specs = synthesizer.synthesize_spectrograms(texts, embeds)\n",
    "    spec = specs[0]\n",
    "    print(\"Created the mel spectrogram\")\n",
    "\n",
    "    # Generating the waveform\n",
    "    print(\"Synthesizing the waveform:\")\n",
    "\n",
    "    generated_wav = vocoder.infer_waveform(spec)\n",
    "\n",
    "    # Post-generation\n",
    "    # There's a bug with sounddevice that makes the audio cut one\n",
    "    # second earlier, so we pad it.\n",
    "    generated_wav = np.pad(generated_wav, (0, synthesizer.sample_rate), mode=\"constant\")\n",
    "\n",
    "    # Trim excess silences to compensate for gaps in spectrograms (issue #53)\n",
    "    generated_wav = encoder.preprocess_wav(generated_wav)\n",
    "\n",
    "    # Play the audio (non-blocking)\n",
    "    try:\n",
    "        sd.stop()\n",
    "        sd.play(generated_wav, synthesizer.sample_rate)\n",
    "    except sd.PortAudioError as e:\n",
    "        print(\"\\nCaught exception: %s\" % repr(e))\n",
    "        print(\n",
    "            'Continuing without audio playback. Suppress this message with \\\n",
    "            the \"--no_sound\" flag.\\n'\n",
    "        )\n",
    "\n",
    "    # Save it on the disk\n",
    "    filename = \"demo_output_%02d.wav\" % num_generated\n",
    "    sf.write(filename, generated_wav.astype(np.float32), synthesizer.sample_rate)\n",
    "    num_generated += 1\n",
    "    print(\"\\nSaved output as %s\\n\\n\" % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
